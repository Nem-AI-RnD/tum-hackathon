{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b069a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-17T13:57:51.638282Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2173031625, 'load_duration': 1753744292, 'prompt_eval_count': 29, 'prompt_eval_duration': 209380916, 'eval_count': 18, 'eval_duration': 208758792, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-77f482d2-a8e6-4774-9fe9-4551ee7017ed-0', usage_metadata={'input_tokens': 29, 'output_tokens': 18, 'total_tokens': 47})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af00c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from ai_eval.config import global_config as glob\n",
    "\n",
    "embedding_model = VertexAIEmbeddings(\n",
    "    project=glob.GCP_PROJECT, model_name=\"text-embedding-004\"\n",
    ")\n",
    "\n",
    "llm = ChatVertexAI(model_name=\"gemini-2.0-flash-001\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b311fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, model=\"llama3.2\"):\n",
    "        self.llm = llm\n",
    "        self.embeddings = embedding_model\n",
    "        self.doc_embeddings = None\n",
    "        self.docs = None\n",
    "\n",
    "    def load_documents(self, documents):\n",
    "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
    "        self.docs = documents\n",
    "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "\n",
    "    def get_most_relevant_docs(self, query):\n",
    "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
    "        if not self.docs or not self.doc_embeddings:\n",
    "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
    "\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        similarities = [\n",
    "            np.dot(query_embedding, doc_emb)\n",
    "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
    "            for doc_emb in self.doc_embeddings\n",
    "        ]\n",
    "        most_relevant_doc_index = np.argmax(similarities)\n",
    "        return [self.docs[most_relevant_doc_index]]\n",
    "\n",
    "    def generate_answer(self, query, relevant_doc):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"human\", prompt),\n",
    "        ]\n",
    "        ai_msg = self.llm.invoke(messages)\n",
    "        return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce154bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b24ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who introduced the theory of relativity?\n",
      "Relevant Document: ['Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.']\n",
      "Answer: According to the document, Albert Einstein introduced the theory of relativity.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG instance\n",
    "rag = RAG()\n",
    "\n",
    "# Load documents\n",
    "rag.load_documents(sample_docs)\n",
    "\n",
    "# Query and retrieve the most relevant document\n",
    "query = \"Who introduced the theory of relativity?\"\n",
    "relevant_doc = rag.get_most_relevant_docs(query)\n",
    "\n",
    "# Generate an answer\n",
    "answer = rag.generate_answer(query, relevant_doc)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Relevant Document: {relevant_doc}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a1c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"Who introduced the theory of relativity?\",\n",
    "    \"Who was the first computer programmer?\",\n",
    "    \"What did Isaac Newton contribute to science?\",\n",
    "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
    "    \"What is the theory of evolution by natural selection?\"\n",
    "]\n",
    "\n",
    "expected_responses = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3cb9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for query,reference in zip(sample_queries,expected_responses):\n",
    "\n",
    "    relevant_docs = rag.get_most_relevant_docs(query)\n",
    "    response = rag.generate_answer(query, relevant_docs)\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c78b5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'response', 'reference'], len=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d97bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 6/15 [02:36<07:10, 47.81s/it]Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Evaluating:  47%|████▋     | 7/15 [03:00<05:18, 39.87s/it]Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 15/15 [03:00<00:00, 12.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.9000, 'faithfulness': nan, 'factual_correctness(mode=f1)': 1.0000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1121b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "filename = \"20240731_Nemetschek SE_Mitarbeiterhandbuch_Employee Handbook.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(f\"{glob.DATA_PKG_DIR}/{filename}\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb31a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/18 [00:00<?, ?it/s]unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "Applying HeadlineSplitter:   0%|          | 0/19 [00:00<?, ?it/s]  unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:   0%|          | 0/18 [00:00<?, ?it/s]unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "unable to apply transformation: object of type 'StringPromptValue' has no len()\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/18 [00:00<?, ?it/s]unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]      unable to apply transformation: Node 2a0b8130-15ac-478d-8a4d-8ea6bf789832 has no summary_embedding\n",
      "                                                                                              \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No nodes that satisfied the given filer. Try changing the filter.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtestset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestsetGenerator\n\u001b[32m      3\u001b[39m generator = TestsetGenerator(llm=llm, embedding_model=generator_embeddings)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Team/ai-assistant-eval/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:188\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    185\u001b[39m apply_transforms(kg, transforms)\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.knowledge_graph = kg\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Team/ai-assistant-eval/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:369\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    366\u001b[39m     patch_logger(\u001b[33m\"\u001b[39m\u001b[33mragas.experimental.testset.transforms\u001b[39m\u001b[33m\"\u001b[39m, logging.DEBUG)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persona_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28mself\u001b[39m.persona_list = \u001b[43mgenerate_personas_from_kg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mknowledge_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_personas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_personas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    376\u001b[39m     random.shuffle(\u001b[38;5;28mself\u001b[39m.persona_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Team/ai-assistant-eval/.venv/lib/python3.12/site-packages/ragas/testset/persona.py:95\u001b[39m, in \u001b[36mgenerate_personas_from_kg\u001b[39m\u001b[34m(kg, llm, persona_generation_prompt, num_personas, filter_fn, callbacks)\u001b[39m\n\u001b[32m     93\u001b[39m nodes = [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m kg.nodes \u001b[38;5;28;01mif\u001b[39;00m filter_fn(node)]\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nodes) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     96\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo nodes that satisfied the given filer. Try changing the filter.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m     )\n\u001b[32m     99\u001b[39m summaries = [node.properties.get(\u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[32m    100\u001b[39m summaries = [summary \u001b[38;5;28;01mfor\u001b[39;00m summary \u001b[38;5;129;01min\u001b[39;00m summaries \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(summary, \u001b[38;5;28mstr\u001b[39m)]\n",
      "\u001b[31mValueError\u001b[39m: No nodes that satisfied the given filer. Try changing the filter."
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1d844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
